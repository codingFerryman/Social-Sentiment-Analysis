{
    "model_name_or_path": "roberta-base",
    "data_load_ratio": 0.0001,
    "model_type": "transformers",
    "tokenizer_type": "transformers",
    "args": {
        "epochs": 3,
        "batch_size": 32,
        "adafactor": true,
        "warmup_steps": 100,
        "weight_decay": 0.0001,
        "learning_rate": 1e-5,
        "evaluation_strategy": "epoch",
        "logging_strategy": "steps",
        "logging_steps": 100,
        "overwrite_output_dir": true,
        "load_best_model_at_end": true,
        "metric_for_best_model": "accuracy",
        "train_val_split_iterator": "train_test_split",
        "stratify": true,
        "test_size": 0.2,
        "fine_tune_layers": {
            "freeze": true,
            "num_unfrozen_layers": 0,
            "unfrozen_embeddings": false
        }
    },
    "tokenizer_config": {
        "add_special_tokens": true,
        "max_length": 32,
        "padding": "max_length",
        "truncation": true,
        "return_token_type_ids": true,
        "return_attention_mask": true
    },
    "model_config": {
        "num_labels": 2,
        "problem_type": "single_label_classification",
        "output_attentions": false,
        "output_hidden_states": false
    },
    "metric": [
        "glue",
        "mrpc"
    ],
    "description": "Test default Roberta model"
}