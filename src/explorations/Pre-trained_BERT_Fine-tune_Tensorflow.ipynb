{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "“CIL_Project_pre-trained_BERT.ipynb”-Copy-25_March",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1VHvnJNCF_bmoKY-d0qMPoMnpYj9YpQBh",
      "authorship_tag": "ABX9TyNeGcfIRLZtaByu0BHTN9Mk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/sebastianSbg/Computational-Intelligence-Lab/blob/master/%E2%80%9CCIL_Project_pre_trained_BERT_ipynb%E2%80%9D_Copy_25_March.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use with google drive. Kept here for reference."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "!pip install transformers"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rWwIHPl6YBj",
        "outputId": "9623a1a7-8530-42c3-aa39-9e035ba390c9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from transformers import TFTrainer, TFTrainingArguments"
      ],
      "outputs": [],
      "metadata": {
        "id": "PPChWta7MDqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Load pre-trained tokenizer and classification model"
      ],
      "outputs": [],
      "metadata": {
        "id": "mAEWHpBxy1NK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "def load_tokenizer():\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#berttokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    return tokenizer"
      ],
      "outputs": [],
      "metadata": {
        "id": "sN2_9E9GY6kV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "def load_model():\n",
        "    # https://huggingface.co/transformers/model_doc/bert.html#tfbertforsequenceclassification\n",
        "    model = TFBertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\", \n",
        "        num_labels = 2, \n",
        "        output_attentions = False, \n",
        "        output_hidden_states = False,\n",
        "    )\n",
        "    return model"
      ],
      "outputs": [],
      "metadata": {
        "id": "vJmEA3n-YHe_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Load the dataset from Google Drive\n",
        "data_path = '/content/drive/MyDrive/twitter-datasets'\n",
        "\n",
        "for dirname, _, filenames in os.walk(data_path):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/twitter-datasets/train_pos_full.txt\n",
            "/content/drive/MyDrive/twitter-datasets/train_neg_full.txt\n",
            "/content/drive/MyDrive/twitter-datasets/test_data.txt\n",
            "/content/drive/MyDrive/twitter-datasets/train_pos.txt\n",
            "/content/drive/MyDrive/twitter-datasets/train_neg.txt\n",
            "/content/drive/MyDrive/twitter-datasets/sample_submission.csv\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA_oDcdLsO2O",
        "outputId": "f8f2ca90-e703-49e1-9447-479a9c316eb0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "with open('/content/drive/MyDrive/twitter-datasets/train_pos.txt', 'r') as fp:\n",
        "    train_pos_sub = fp.readlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/twitter-datasets/train_neg.txt', 'r') as fp:\n",
        "    train_neg_sub = fp.readlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/twitter-datasets/train_pos_full.txt', 'r') as fp:\n",
        "    train_pos_full = fp.readlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/twitter-datasets/train_neg_full.txt', 'r') as fp:\n",
        "    train_neg_full = fp.readlines()\n",
        "\n",
        "with open('/content/drive/MyDrive/twitter-datasets/test_data.txt', 'r') as fp:\n",
        "    test = fp.readlines()"
      ],
      "outputs": [],
      "metadata": {
        "id": "LAmZATQROHQc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# The number of entries in each file\n",
        "len(train_pos_sub), len(train_neg_sub), len(train_pos_full), len(train_neg_full), len(test)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 100000, 1250000, 1250000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bv84AIqOhSB",
        "outputId": "05630ba1-bcf7-4094-d24f-286bdf1bd872"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Use the subsets for this rough exploration\n",
        "data_pos = train_pos_sub\n",
        "data_neg = train_neg_sub"
      ],
      "outputs": [],
      "metadata": {
        "id": "hdexLyyomrYh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# Combine pos & neg, remove <xxxx>\n",
        "text_list = data_pos + data_neg\n",
        "label_list = [1]*len(data_pos) + [0]*len(data_neg)\n",
        "\n",
        "data = {'text': text_list, 'label': label_list}\n",
        "data = DataFrame(data)\n",
        "\n",
        "data['text'] = data['text'].str.replace(r'<.*?>', '')\n",
        "# <user> <url>"
      ],
      "outputs": [],
      "metadata": {
        "id": "biQH0H8SZLoo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# The maximum, minimum number of words in tweets\n",
        "# ... and empty entries\n",
        "min_len = 999\n",
        "max_len = 0\n",
        "zero_len_idx = []\n",
        "for idx, t in enumerate(data.text):\n",
        "    t_len = len(t.split())\n",
        "    if t_len == 0:\n",
        "        zero_len_idx.append(idx)\n",
        "    if t_len > max_len:\n",
        "        max_len = t_len\n",
        "    if t_len < min_len:\n",
        "        min_len = t_len\n",
        "\n",
        "min_len, max_len, len(zero_len_idx)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 62, 17)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfo8cy5DoBl7",
        "outputId": "81c0ca75-0c1f-4735-e1f1-9efe17c961fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "data = data.drop(zero_len_idx)"
      ],
      "outputs": [],
      "metadata": {
        "id": "EP034dH5ICJV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "source": [
        "list(data.text[0:2])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' i dunno justin read my mention or not . only justin and god knows about that , but i hope you will follow me #believe 15\\n',\n",
              " \"because your logic is so dumb , i won't even crop out your name or your photo . tsk . \\n\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_7lltMXKcfo",
        "outputId": "3ef0cee8-9acd-464f-cbfd-451d5beabf60"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "source": [
        "tokenizer = load_tokenizer()"
      ],
      "outputs": [],
      "metadata": {
        "id": "hXpSwRw_adD_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "source": [
        "# An example of tokenization\n",
        "sample = data.text[0]\n",
        "print(sample)\n",
        "\n",
        "encoded_sample = tokenizer(sample)\n",
        "print(encoded_sample)\n",
        "\n",
        "decoded_sample = tokenizer.decode(encoded_sample['input_ids'])\n",
        "print(decoded_sample)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " i dunno justin read my mention or not . only justin and god knows about that , but i hope you will follow me #believe 15\n",
            "\n",
            "{'input_ids': [101, 1045, 14145, 2080, 6796, 3191, 2026, 5254, 2030, 2025, 1012, 2069, 6796, 1998, 2643, 4282, 2055, 2008, 1010, 2021, 1045, 3246, 2017, 2097, 3582, 2033, 1001, 2903, 2321, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
            "[CLS] i dunno justin read my mention or not. only justin and god knows about that, but i hope you will follow me # believe 15 [SEP]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JQVV5sd3-9I",
        "outputId": "6d6cbe10-ba6d-411c-d531-347b7f90dcc3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(Maybe we can keep the hashtag as a special information, it might be useful. But not sure.)"
      ],
      "metadata": {
        "id": "bnDNYDcC4SsP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "source": [
        "# Shuffle the dataset and split it to train- and validation- set\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "val_frac = 0.2\n",
        "val_rows = int(len(data) * val_frac)\n",
        "train = data[:-val_rows]\n",
        "val = data[-val_rows:]"
      ],
      "outputs": [],
      "metadata": {
        "id": "kPb0K3HACJoj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "source": [
        "def encode_dataset(dataset, tokenizer, max_length=64):\n",
        "    enc = tokenizer(\n",
        "        list(dataset.text), \n",
        "        add_special_tokens=True, \n",
        "        truncation=True, \n",
        "        padding=True, \n",
        "        max_length=max_length\n",
        "        )\n",
        "    \n",
        "    enc_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "            dict(enc),\n",
        "            list(dataset.label)\n",
        "            ))\n",
        "    return enc_dataset"
      ],
      "outputs": [],
      "metadata": {
        "id": "jaYkWxpx9X3S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "source": [
        "train_dataset = encode_dataset(train, tokenizer, max_len)\n",
        "val_dataset = encode_dataset(val, tokenizer, max_len)"
      ],
      "outputs": [],
      "metadata": {
        "id": "ni9nxf6mLWX_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "source": [
        "train_dataset = train_dataset.shuffle(1000).batch(32).repeat(2)\n",
        "val_dataset = val_dataset.batch(32)"
      ],
      "outputs": [],
      "metadata": {
        "id": "722dxrOxTJna"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics=[tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]"
      ],
      "outputs": [],
      "metadata": {
        "id": "5oa1AfbnL1T2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "source": [
        "model = load_model()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "metadata": {
        "id": "a3SzkidgMq-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a32ce3df-08bb-44b9-a4ff-c9d4a82edd83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "source": [
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Esr-FqKEEQID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "source": [
        "model.fit(train_dataset, epochs=3, validation_data=val_dataset)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f02b679bec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f02b679bec0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f02d204bc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f02d204bc20> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "10000/10000 [==============================] - ETA: 0s - loss: 0.3224 - accuracy: 0.8559WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "10000/10000 [==============================] - 1702s 165ms/step - loss: 0.3224 - accuracy: 0.8559 - val_loss: 0.2984 - val_accuracy: 0.8800\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 1640s 164ms/step - loss: 0.1294 - accuracy: 0.9505 - val_loss: 0.5655 - val_accuracy: 0.8747\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 1639s 164ms/step - loss: 0.0568 - accuracy: 0.9792 - val_loss: 0.6108 - val_accuracy: 0.8736\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f02008118d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyWg7uFgER9C",
        "outputId": "bcde17af-6259-4771-f27b-e6bb390579c1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "source": [
        "model_saved_path = '/content/drive/MyDrive/CIL/model_BERT_pre_trained'\n",
        "model.save(model_saved_path)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, encoder_layer_call_fn, encoder_layer_call_and_return_conditional_losses, pooler_layer_call_fn while saving (showing 5 of 1055). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CIL/model_BERT_pre_trained/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/CIL/model_BERT_pre_trained/assets\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHBHX5Y-Tb7F",
        "outputId": "2f1748fd-e23f-46b3-8af5-841c0106a212"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "v3bxzaG83D3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# model = tf.keras.models.load_model(model_saved_path)"
      ],
      "outputs": [],
      "metadata": {
        "id": "4dahl0FI1KUR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_dataset = [re.sub(r'<.*?>', '', t) for t in test]"
      ],
      "outputs": [],
      "metadata": {
        "id": "9e_iSVVz3D8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "test_dataset = tokenizer_pretrained(\n",
        "        list(test_dataset), \n",
        "        add_special_tokens=True, \n",
        "        truncation=True, \n",
        "        padding=True, \n",
        "        max_length=max_len\n",
        "        )"
      ],
      "outputs": [],
      "metadata": {
        "id": "7qU7qtV_w4pT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "tf_outputs = model.predict(test_dataset.input_ids)\n",
        "tf_predictions = tf.nn.softmax(tf_outputs[0], axis=-1)\n",
        "label = tf.argmax(tf_predictions, axis=1)\n",
        "label = label.numpy()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r3Dhq892zye",
        "outputId": "e4fa7f00-9e51-4de1-84c7-7c565af4d04f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "label"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxd173lMW63C",
        "outputId": "14888520-7392-4a67-b731-0af7959be4fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred = np.where(label==0, -1, label)\n",
        "pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1, -1,  1, ..., -1,  1, -1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXMF2i59XO2r",
        "outputId": "0ee009a3-ac9b-4c08-b8fa-86045b692034"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_dict = {'Id': range(1, 1+len(pred)), 'Prediction': pred}"
      ],
      "outputs": [],
      "metadata": {
        "id": "xr_ZjULlYCh6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_df = DataFrame(pred_dict)\n",
        "pred_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Id  Prediction\n",
              "0   1          -1\n",
              "1   2          -1\n",
              "2   3           1\n",
              "3   4           1\n",
              "4   5          -1"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ArWrBEykYTqx",
        "outputId": "b0a266cd-ef79-4620-ef99-fbd33f8a7012"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "pred_df.to_csv('./submission.csv', index=False)"
      ],
      "outputs": [],
      "metadata": {
        "id": "7AguRGjYYh07"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: \n",
        "- https://huggingface.co/transformers/custom_datasets.html#sequence-classification-with-imdb-reviews\n",
        "- https://colab.research.google.com/drive/1CzEAyAByzXl5rZBYVBVeVcjT5fl3zTfb?usp=sharing\n",
        "- https://www.tensorflow.org/tutorials/text/text_classification_rnn"
      ],
      "metadata": {
        "id": "HV-xI4rLmPky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We might use RNN as the other baseline"
      ],
      "metadata": {
        "id": "k3MH5KORhYFS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "FLOI0EYJX0XI"
      }
    }
  ]
}