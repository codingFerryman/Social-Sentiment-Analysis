{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datetime as dt\n",
    "import enum\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import hyperopt\n",
    "import hyperopt.pyll\n",
    "import numpy as np\n",
    "from datasets import list_metrics\n",
    "from transformers import logging as hf_logging\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from utils import get_project_path, get_transformers_layers_num, loggers\n",
    "from models.Model import ModelConstruction\n",
    "from models.transformersModel import TransformersModel\n",
    "from preprocessing.cleaningText import cleaningMap\n",
    "from preprocessing.pretrainedTransformersPipeline import PretrainedTransformersPipeLine\n",
    "\n",
    "PROJECT_DIRECTORY = get_project_path()\n",
    "\n",
    "# hf_logging.set_verbosity_error()\n",
    "hf_logging.enable_explicit_format()\n",
    "logger = loggers.getLogger(\"Notebook\", debug=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data folder is set to `/home/sniper/projects_local/CIL/Computational-Intelligence-Lab/venv/lib64/python3.9/site-packages/neuspell/../data` script\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Since the GPL-licensed package `unidecode` is not installed, using Python's `unicodedata` package which yields worse results.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "d = {}\n",
    "with open(\"/home/sniper/projects_local/CIL/Computational-Intelligence-Lab/src/configs/dev/squeezebert.json\") as fr:\n",
    "    d = json.load(fr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "model_name_or_path = d['model_name_or_path']\n",
    "tokenizer_name_or_path = d.get('tokenizer_name_or_path', model_name_or_path)\n",
    "model = TransformersModel(modelName_or_pipeLine=model_name_or_path,\n",
    "                            tokenizer_name_or_path=tokenizer_name_or_path,\n",
    "                            fast_tokenizer=d.get('fast_tokenizer'),\n",
    "                            text_pre_cleaning=d.get('text_pre_cleaning', 'default'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-26 04:24:09] - PretrainedTransformersPipeLine - {line:76} INFO - PretrainedTransformersPipeLine created\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if type(d['metric']) is str:\n",
    "        d['metric'] = [d['metric']]\n",
    "assert (d['metric'][0] in list_metrics()), \\\n",
    "        f\"The metric for evaluation is not supported.\\n\" \\\n",
    "        f\"It should be in https://huggingface.co/metrics\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model.registerMetric(*d['metric'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.loadData(ratio=d['data_load_ratio'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-26 04:24:14] - PretrainedTransformersPipeLine - {line:113} INFO - loading data for PretrainedTransformersPipeLine squeezebert/squeezebert-uncased\n",
      "[2021-07-26 04:24:15] - InputPipeline - {line:66} INFO - Dataset loaded!\n",
      "[2021-07-26 04:24:15] - InputPipeline - {line:67} DEBUG - Positive: 338, Negative: 342, Test: 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "text_pre_cleaning_function = cleaningMap(\"masks\")\n",
    "logger.info('Cleaning the dataset ...')\n",
    "allData = text_pre_cleaning_function(model.pipeLine.allData)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[2021-07-26 04:24:18] - Notebook - {line:2} INFO - Cleaning the dataset ...\n",
      "FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from dateutil import parser\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def lemmatize(input):\n",
    "    \"\"\"\n",
    "    Lemmatizes input using NLTK's WordNetLemmatizer\n",
    "    \"\"\"\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    input_str=word_tokenize(input)\n",
    "    new_words = []\n",
    "    for word in input_str:\n",
    "        new_words.append(lemmatizer.lemmatize(word))\n",
    "    return ' '.join(new_words)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sniper/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/sniper/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sniper/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "tt = TweetTokenizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "dataTokenized = [tt.tokenize(dat) for dat in allData]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dataLematized = lemmatize(' '.join([' '.join(m) for m in dataTokenized]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import gensim.corpora as corpora\n",
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(dataTokenized)\n",
    "# Create Corpus\n",
    "corpus = [id2word.doc2bow(text) for text in dataTokenized]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import gensim"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "num_topics = 10 # positive/negative\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=num_topics)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "with open(\"../../data/test_data.txt\") as fr:\n",
    "    testTweets = fr.readlines()\n",
    "testTweetsTokenized = [tt.tokenize(testTweet) for testTweet in testTweets]\n",
    "# \n",
    "# lda_model[testTweetsTokenized[0]]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "from gensim.test.utils import common_corpus, common_dictionary\n",
    "testTweetBow = [common_dictionary.doc2bow(tweet) for tweet in testTweetsTokenized]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "testTweetsVectors = np.array([lda_model[it] for it in testTweetBow])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "vectorProbabilities = testTweetsVectors[:,:,1]\n",
    "test_topics = np.argmax(vectorProbabilities, axis=-1)\n",
    "print(test_topics)\n",
    "# print()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "import pyLDAvis\n",
    "# from pyLDAvis import gensim_models \n",
    "import pickle \n",
    "\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from pyLDAvis import gensim as gensimvis\n",
    "# from pyLDAvis import gensim_models \n",
    "LDAvis_data_filepath = os.path.join(f'./ldavis_prepared2_{num_topics}.ld')\n",
    "\n",
    "## This is a bit time consuming - make the if statement True\n",
    "## if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "LDAvis_prepared"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'LDAvis_prepared' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db7adb93f5f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLDAvis_prepared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'LDAvis_prepared' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# encodedDatasetArgs = {'splitter': splitter,\n",
    "#                               'tokenizerConfig': tokenizer_config,\n",
    "#                               'cleaning_function': text_pre_cleaning_function}\n",
    "\n",
    "# logger.info('Cleaned!')\n",
    "# for train_dataset, val_dataset in model.pipeLine.getEncodedDataset(**encodedDatasetArgs):\n",
    "#             pass"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('venv': venv)"
  },
  "interpreter": {
   "hash": "60c5f45b5ba2ea48f97ffcec27ef9eebc28b2201c447d17a973179b0efd4056c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}