{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path, PurePath\n",
    "from typing import List, Collection\n",
    "\n",
    "import git\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, RobertaConfig\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import EarlyStoppingCallback\n",
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print GPU info, set default device and empty cache\n",
    "print(torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    gpu_count = torch.cuda.device_count()\n",
    "    for i in range(gpu_count):\n",
    "        print(torch.cuda.get_device_properties(i))\n",
    "device = torch.device('cuda:'+str(gpu_count-1) if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "    use_fp16 = False\n",
    "    PROJECT_ROOT = git.Repo(PurePath(), search_parent_directories=True).git.rev_parse(\"--show-toplevel\")\n",
    "    DATA_ROOT = PurePath(PROJECT_ROOT, \"data\")\n",
    "else:\n",
    "    from google.colab import drive\n",
    "    use_fp16 = True\n",
    "    drive.mount('/content/drive')\n",
    "    PROJECT_ROOT = PurePath('')\n",
    "    DATA_ROOT = Path('/content/drive/MyDrive/twitter-datasets')\n",
    "\n",
    "\n",
    "with open(PurePath(DATA_ROOT, 'train_pos.txt'), 'r', encoding='utf-8') as fp:\n",
    "    train_pos_sub = fp.readlines()\n",
    "\n",
    "with open(PurePath(DATA_ROOT, 'train_neg.txt'), 'r', encoding='utf-8') as fp:\n",
    "    train_neg_sub = fp.readlines()\n",
    "\n",
    "with open(PurePath(DATA_ROOT, 'train_pos_full.txt'), 'r', encoding='utf-8') as fp:\n",
    "    train_pos_full = fp.readlines()\n",
    "\n",
    "with open(PurePath(DATA_ROOT, 'train_neg_full.txt'), 'r', encoding='utf-8') as fp:\n",
    "    train_neg_full = fp.readlines()\n",
    "\n",
    "with open(PurePath(DATA_ROOT, 'test_data.txt'), 'r', encoding='utf-8') as fp:\n",
    "    test_full = fp.readlines()\n",
    "\n",
    "def load_dataset(ratio=0.01):\n",
    "    if type(ratio) is int:\n",
    "        ratio = float(ratio)\n",
    "    assert isinstance(ratio, str) or isinstance(ratio, float)\n",
    "    if type(ratio) is float:\n",
    "        if ratio <= 0 or ratio > 1:\n",
    "            raise AttributeError('The input should be \\'full\\', \\'sub\\', or a (float) number between 0 and 1')\n",
    "        num_samples = int(ratio*len(train_pos_full))\n",
    "        return random.sample(train_pos_full, num_samples), random.sample(train_neg_full, num_samples)\n",
    "    else:\n",
    "        if ratio == 'full':\n",
    "            return train_pos_full, train_neg_full\n",
    "        elif ratio == 'sub':\n",
    "            return train_pos_sub, train_neg_sub\n",
    "        else:\n",
    "            raise AttributeError('The input should be \\'full\\', \\'sub\\', or a (float) number between 0 and 1')\n",
    "\n",
    "data_pos, data_neg = load_dataset(0.05)\n",
    "print(len(data_pos), len(data_neg), len(test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pre-processing function besides tokenizers\n",
    "def cleaning(text_list: list) -> List:\n",
    "    text_list = [re.sub(r'(<.*?>)|(\\r\\n|\\r|\\n)|(\\'|\\\")', '', s.lstrip()) for s in text_list]\n",
    "    return list(filter(lambda x: x != \"\", text_list))\n",
    "\n",
    "data_pos, data_neg, data_test = list(set(cleaning(data_pos))), list(set(cleaning(data_neg))), cleaning(test_full)\n",
    "print(len(data_pos), len(data_neg), len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum, minimum number of words in tweets\n",
    "# ... and empty entries\n",
    "def get_min_max(text_list: list) -> (int, int, List):\n",
    "    min_len = 999\n",
    "    max_len = 0\n",
    "    zero_len_idx = []\n",
    "    for idx, t in enumerate(text_list):\n",
    "        t_len = len(t.split())\n",
    "        if t_len == 0:\n",
    "            zero_len_idx.append(idx)\n",
    "        if t_len > max_len:\n",
    "            max_len = t_len\n",
    "        if t_len < min_len:\n",
    "            min_len = t_len\n",
    "    return min_len, max_len, zero_len_idx\n",
    "\n",
    "test = [s.split(',', 1)[-1] for s in data_test]\n",
    "min_test, max_test, zero_len_idx_test = get_min_max(test)\n",
    "print(min_test, max_test, zero_len_idx_test, len(test))\n",
    "test_text = list(filter(lambda x: x != \"\", test))\n",
    "print(len(test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ids of the items in test_text\n",
    "test_id = list(set(range(1, len(data_test)+1)) - set(zero_len_idx_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config pre-trained tokenizers and models\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base'\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "}\n",
    "\n",
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ROOT = PurePath(PROJECT_ROOT, \".pretrained_models\", pretrained_model_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "tokenizer.save_pretrained(MODEL_ROOT)\n",
    "\n",
    "config = config_class.from_pretrained(pretrained_model_name)\n",
    "config.num_labels = num_classes\n",
    "config.use_bfloat16 = use_fp16\n",
    "config.problem_type = \"single_label_classification\"\n",
    "config.save_pretrained(MODEL_ROOT)\n",
    "\n",
    "model = model_class.from_pretrained(pretrained_model_name, config=config)\n",
    "model.save_pretrained(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset and split it to train- and validation- set\n",
    "train_texts = data_pos + data_neg\n",
    "train_labels = [1]*len(data_pos) + [0]*len(data_neg)\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "len(train_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, text_list: list, labels_list: list, max_length: int, tokenizer=tokenizer):\n",
    "        self.encodings = tokenizer(text_list, truncation=True, padding='max_length', max_length=max_length)\n",
    "        self.labels = labels_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode datasets\n",
    "train_dataset, val_dataset = TweetDataset(train_texts, train_labels, max_test), TweetDataset(val_texts, val_labels, max_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load back model\n",
    "config = config_class.from_pretrained(MODEL_ROOT)\n",
    "model = model_class.from_pretrained(MODEL_ROOT, config=config)\n",
    "# ... and print model structure\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify frozen layers\n",
    "if 'roberta-base' in pretrained_model_name:\n",
    "    num_layers = 12\n",
    "elif 'roberta-large' in pretrained_model_name:\n",
    "    num_layers = 24\n",
    "\n",
    "frozen_layers = ['embeddings'] + ['layer.' + str(i) for i in range(int(num_layers*0.75)) ]\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    for frozen_name in frozen_layers:\n",
    "        if frozen_name in name:\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=PurePath(PROJECT_ROOT, '.trainer', pretrained_model_name), \n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=1500,\n",
    "    per_device_eval_batch_size=1500,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=PurePath(PROJECT_ROOT, '.trainer', pretrained_model_name, 'logs'),\n",
    "    evaluation_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    fp16=use_fp16,\n",
    "    # group_by_length=True,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(MODEL_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "test_loader = DataLoader(test_text, batch_size=1000)\n",
    "predictions = torch.tensor([], device=device)\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        inputs = tokenizer(test_data, truncation=True, padding='max_length', max_length=max_test, return_tensors=\"pt\")\n",
    "        inputs = inputs.to(device)\n",
    "        logit = model(**inputs).logits\n",
    "        prediction = torch.argmax(torch.softmax(logit,dim=-1), dim=-1)\n",
    "        predictions = torch.cat((predictions, prediction), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions be compatible with the submission\n",
    "pred = predictions.int().tolist()\n",
    "# pred = np.where(pred==0, -1, pred)\n",
    "pred_id = test_id+zero_len_idx_test\n",
    "pred_est = pred+[random.choice([0,1]) for i in range(len(zero_len_idx_test))]\n",
    "pred_est = [p if p==1 else -1 for p in pred_est]\n",
    "pred_dict = {'Id': pred_id, 'Prediction': pred_est}\n",
    "pred_df = pd.DataFrame(pred_dict)\n",
    "pred_df.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3810jvsc74a57bd010e8cd3db9af619636183193d03796976e9bfe2b677e014039b52324af88f919",
   "display_name": "Python 3.8.10 64-bit ('CIL': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}