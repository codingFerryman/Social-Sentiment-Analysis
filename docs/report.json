{
    "num_experiments": 4,
    "experiments": [
        {
            "results": [
                100,
                100
            ],
            "output_dir": "./results/roberta",
            "description": "dummy roberta test for debugging"
        },
        {
            "results": [
                50,
                50
            ],
            "output_dir": "./results/roberta",
            "description": "dummy roberta test for debugging 2"
        },
        {
            "model_name_or_path": "roberta-base",
            "data_load_ratio": 0.001,
            "model_type": "transformers",
            "tokenizer_type": "transformers",
            "args": {
                "adafactor": true,
                "warmup_steps": 100,
                "weight_decay": 0.0001,
                "learning_rate": 1e-05,
                "evaluation_strategy": "epoch",
                "logging_strategy": "steps",
                "logging_steps": 100,
                "overwrite_output_dir": true,
                "load_best_model_at_end": true,
                "metric_for_best_model": "accuracy",
                "num_train_epochs": 3,
                "per_device_train_batch_size": 32,
                "per_device_eval_batch_size": 32
            },
            "tokenizer_config": {
                "add_special_tokens": true,
                "max_length": 32,
                "padding": "max_length",
                "truncation": true,
                "return_token_type_ids": true,
                "return_attention_mask": true
            },
            "model_config": {
                "num_labels": 2,
                "problem_type": "single_label_classification",
                "output_attentions": false,
                "output_hidden_states": false
            },
            "metric": [
                "glue",
                "mrpc"
            ],
            "description": "Roberta model for testing framework",
            "results": {
                "accuracy": 0.584
            },
            "output_dir": "/home/sniper/projects_local/CIL/Computational-Intelligence-Lab/trainings/logging/roberta-base/20210706-125038/checkpoints/checkpoint-189",
            "time_stamp": "2021-07-06 12:59:36.004492"
        },
        {
            "model_name_or_path": "roberta-base",
            "data_load_ratio": 0.001,
            "model_type": "transformers",
            "tokenizer_type": "transformers",
            "args": {
                "adafactor": true,
                "warmup_steps": 100,
                "weight_decay": 0.0001,
                "learning_rate": 1e-05,
                "evaluation_strategy": "epoch",
                "logging_strategy": "steps",
                "logging_steps": 100,
                "overwrite_output_dir": true,
                "load_best_model_at_end": true,
                "metric_for_best_model": "accuracy",
                "num_train_epochs": 3,
                "per_device_train_batch_size": 32,
                "per_device_eval_batch_size": 32
            },
            "tokenizer_config": {
                "add_special_tokens": true,
                "max_length": 32,
                "padding": "max_length",
                "truncation": true,
                "return_token_type_ids": true,
                "return_attention_mask": true
            },
            "model_config": {
                "num_labels": 2,
                "problem_type": "single_label_classification",
                "output_attentions": false,
                "output_hidden_states": false
            },
            "metric": [
                "glue",
                "mrpc"
            ],
            "description": "Test default Roberta model",
            "results": {
                "accuracy": 0.644
            },
            "output_dir": "/home/sniper/projects_local/CIL/Computational-Intelligence-Lab/trainings/logging/roberta-base/20210706-132352/checkpoints/checkpoint-126",
            "time_stamp": "2021-07-06 13:32:59.303694"
        }
    ]
}