{
    "num_experiments": 3,
    "experiments": [
        {
            "model_name_or_path": "vinai/bertweet-base",
            "data_load_ratio": 1,
            "model_type": "transformers",
            "tokenizer_type": "transformers",
            "args": {
                "adafactor": true,
                "warmup_steps": 100,
                "weight_decay": 0.0001,
                "learning_rate": 1e-05,
                "evaluation_strategy": "epoch",
                "logging_strategy": "steps",
                "logging_steps": 100,
                "overwrite_output_dir": true,
                "load_best_model_at_end": true,
                "metric_for_best_model": "accuracy",
                "num_train_epochs": 3,
                "per_device_train_batch_size": 384,
                "per_device_eval_batch_size": 384
            },
            "tokenizer_config": {
                "add_special_tokens": true,
                "max_length": 50,
                "padding": "max_length",
                "truncation": true,
                "return_token_type_ids": true,
                "return_attention_mask": true
            },
            "model_config": {
                "num_labels": 2,
                "problem_type": "single_label_classification",
                "output_attentions": false,
                "output_hidden_states": false
            },
            "metric": [
                "glue",
                "mrpc"
            ],
            "description": "vinai/bertweet-base w/ full dataset",
            "results": {
                "accuracy": 0.888752
            },
            "output_dir": "/cluster/home/heliuhe/cil-project/trainings/logging/vinai/bertweet-base/20210704-164012/checkpoints/checkpoint-15627",
            "time_stamp": "2021-07-04 21:59:18.156379"
        },
        {
            "model_name_or_path": "siebert/sentiment-roberta-large-english",
            "data_load_ratio": 1,
            "model_type": "transformers",
            "tokenizer_type": "transformers",
            "args": {
                "epochs": 5,
                "batch_size": 128,
                "adafactor": true,
                "warmup_steps": 100,
                "weight_decay": 0.0001,
                "learning_rate": 1e-5,
                "evaluation_strategy": "epoch",
                "logging_strategy": "steps",
                "logging_steps": 100,
                "overwrite_output_dir": true,
                "load_best_model_at_end": true,
                "metric_for_best_model": "accuracy",
                "train_val_split_iterator": "train_test_split",
                "fine_tune_layers": {
                    "freeze": true,
                    "num_unfrozen_layers": 1,
                    "unfrozen_embeddings": false
                }
            },
            "tokenizer_config": {
                "add_special_tokens": true,
                "max_length": 50,
                "padding": "max_length",
                "truncation": true,
                "return_token_type_ids": true,
                "return_attention_mask": true
            },
            "model_config": {
                "num_labels": 2,
                "problem_type": "single_label_classification",
                "output_attentions": false,
                "output_hidden_states": false
            },
            "metric": [
                "glue",
                "mrpc"
            ],
            "description": "siebert/sentiment-roberta-large-english",
            "results": {
                "accuracy": 0.857706
            },
            "output_dir": "/cluster/home/heliuhe/cil-project/trainings/logging/siebert/sentiment-roberta-large-english/20210704-234431/checkpoints/checkpoint-62500",
            "time_stamp": "2021-07-05 06:57:18.845612"
        },
        {
            "model_name_or_path": "vinai/bertweet-base",
            "data_load_ratio": 1,
            "model_type": "transformers",
            "tokenizer_type": "transformers",
            "args": {
                "adafactor": true,
                "warmup_steps": 100,
                "weight_decay": 0.0001,
                "learning_rate": 1e-05,
                "evaluation_strategy": "epoch",
                "logging_strategy": "steps",
                "logging_steps": 100,
                "overwrite_output_dir": true,
                "load_best_model_at_end": true,
                "metric_for_best_model": "accuracy",
                "num_train_epochs": 3,
                "per_device_train_batch_size": 384,
                "per_device_eval_batch_size": 384,
                "fp16": true
            },
            "tokenizer_config": {
                "add_special_tokens": true,
                "max_length": 50,
                "padding": "max_length",
                "truncation": true,
                "return_token_type_ids": true,
                "return_attention_mask": true
            },
            "model_config": {
                "num_labels": 2,
                "problem_type": "single_label_classification",
                "output_attentions": false,
                "output_hidden_states": false,
                "id2label": {
                    "1": 1,
                    "0": -1
                }
            },
            "metric": [
                "glue",
                "mrpc"
            ],
            "description": "vinai/bertweet-base w/ full dataset",
            "results": {
                "accuracy": 0.891444
            },
            "output_dir": "/cluster/home/heliuhe/cil-project/trainings/logging/vinai/bertweet-base/20210705-131541/checkpoints/checkpoint-15627",
            "time_stamp": "2021-07-05 15:34:46.276563"
        }
    ]
}
